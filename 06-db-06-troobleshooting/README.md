# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
   
    Зайти в оболочку mongo и выполнить команду db.currentOp(), в ее выводе получить идентификатор
    opid, например - "opid" : 27067791
```shell
> db.currentOp()
{
	"inprog" : [
		{
			"desc" : "conn34",
			"threadId" : "139878091196160",
			"connectionId" : 34,
			"client" : "127.0.0.1:36934",
			"active" : true,
			"opid" : 27067791,
			"secs_running" : 0,
			"microsecs_running" : NumberLong(20),
			"op" : "command",
			"ns" : "admin.$cmd",
			"query" : {
				"currentOp" : 1
			},
			"numYields" : 0,
			"locks" : {
				
			},
			"waitingForLock" : false,
			"lockStats" : {
				
			}
		}
	],
	"ok" : 1
}


    ввести его в качестве аргумента команде db.killOp(27067791)
    для кластера db.killOp("shard_id:opid")
```

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

    необходимо включить профилировщик командой db.setProfilingLevel(2)
    

|Уровень|Описание|
| --- | --- |
|0|Профилировщик выключен и не собирает никаких данных. Это уровень профилировщика по умолчанию.|
|1|Профилировщик собирает данные для операций, которые занимают больше времени, чем значение slowmsили соответствуют фильтру.<br/>Когда установлен фильтр:<br/>Параметры slowmsи sampleRateне используются для профилирования.<br/>Профилировщик фиксирует только те операции, которые соответствуют фильтру .|
|2 |Профилировщик собирает данные для всех операций.|

Часто для ускорения работы достаточно настроить соответствующие индесы.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
### В представленной [документации](https://redis.io/topics/latency) описан случай, когда redis блокируется.

Если в базе данных есть много ключей, срок действия которых истекает в одну и ту же секунду, и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия , Redis может заблокировать, чтобы процент ключей, срок действия которых истек, был ниже 25%.


## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

Гис-система обычно оперирует большими объемами данных, указанная ошибка говорит о том, что сервер БД не оптимально настроен на работу с такими объемами.
В приведенной документации для ошибок "Lost connection" указаны 3 основные причины:

- миллионы строк отправляются как часть одного или нескольких запросов, времени на их обработку не хватает (net_read_timeout). 
- при установке первоначального соединения с сервером, если connect_timeout значение установлено всего на несколько секунд, его может не хватить для подключения из-за загруженности сервера.
- проблема с BLOB-значениями, превышающими max_allowed_packet, что может вызвать эту ошибку на некоторых клиентах (т.е. размер пакета превышает максимальное значение в конфиге) данная причина более вероятна, если встречается ошибка ER_NET_PACKET_TOO_LARGE.

Для решения этой проблемы необходимо увеличивать значение параметров net_read_timeout, connect_timeout и max_allowed_packet и смотреть на частоту появления ошибок, также можно увеличить их значительно, а затем уменьшать с небольшим шагом, ориентируясь на частоту возникновения ошибок.

Так же, если определено, что ошибки из-за большого количества строк, имеет смысл оптимизировать ПО, которое обращается к БД, если есть возможность, брать из БД не сразу всё, а порциями. 
Не лишним будет добавить оперативную память серверу БД и проверить-ускорить работу сети.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

В данном случае сработал механизм операционной системы - Out-Of-Memory Killer. Когда у сервера или процесса заканчивается память, Linux предлагает 2 пути решения: обрушить всю систему или завершить процесс (приложение), который съедает память. Лучше, конечно, завершить процесс и спасти ОС от аварийного завершения. В двух словах, Out-Of-Memory Killer — это процесс, который завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС

Для решения данной проблемы потребуется увеличить объем оперативной памяти. Независимо от того, возможно увеличение или нет, необходимо настроить постгрес на рациональное испоьзование оперативной памяти, придерживаясь формулы "Фактическая максимальная оперативная память" = shared_buffers + (temp_buffers + work_mem) * max_connections т.к. в postgres нет параметра, четко определяющего объем используемой RAM и часто бывают ситуации, когда процессы postgres ее (RAM) не освобождают. 

Также есть возможность настроить ОС добавить 

```shell
[Service]
OOMScoreAdjust=-500
```
в файл system unit postgres (например /etc/systemd/system/multi-user.target.wants/postgresql.service).
Такая настройка повысит шансы postgres не стать плохим процессом для OOM-killer, что защитит его от принудительного завершения. 

Еще можно поменять значения переменной vm.overcommit_memory с 0 (чаще всего по-умолчанию, ядро само решает, стоит ли резервировать слишком много памяти), на 2 (ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio).

Приведенные настройки не гарантируют, что OOM-Killer не придется вмешиваться, но снизят вероятность принудительного завершения процесса PostgreSQL

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
